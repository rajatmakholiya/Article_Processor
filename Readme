# AI Content Improver

A monolithic application that automates and enhances article content using AI. It ingests raw articles, gathers competitor insights from the web, rewrites content with Google Gemini AI for greater depth, and presents a side-by-side comparison in a modern dashboard.

---

## 1. Architecture & Data Flow

```mermaid
graph TD
    subgraph Data Ingestion
        A[Raw .docx Files] -->|Python Script| B[(MySQL Database)]
    end

    subgraph Backend [Laravel API]
        B <-->|Read/Write| C[Laravel Controller]
        C <-->|JSON API| D[API Endpoints]
    end

    subgraph Automation [Node.js Worker]
        D -->|Fetch Pending| E[Worker Script]
        E -->|Search Keywords| F[Google Search]
        F -->|Scrape Blogs| G[Competitor Content]
        G -->|Context + Prompt| H[Gemini AI]
        H -->|Enhanced Content| E
        E -->|Update Article| D
    end

    subgraph Frontend [React UI]
        D -->|Fetch Articles| I[Dashboard]
        I -->|Display| J[Comparison View]
    end
```

---

# 2. Workflow Overview

**Ingestion:** Import raw `.docx` articles into MySQL using a Python script.  
**Orchestration:** Laravel backend manages article states (`pending → processing → completed`) and exposes a REST API.  
**Processing:** Node.js worker fetches pending articles, scrapes Google for competitor data, and rewrites content with Gemini AI, including citations.  
**Presentation:** React frontend displays original and AI-enhanced articles side-by-side for easy comparison.

---

# 3. Local Setup Instructions

### Prerequisites
- Docker Desktop (for MySQL & phpMyAdmin)
- Node.js (v18+)
- npm
- PHP (v8.2+) & Composer
- Python 3 (for data import)

### 3.1 Database Setup (Docker)
Start MySQL and phpMyAdmin:

```bash
# In the root project folder
docker-compose up -d
```
- Database: `localhost:3306` (User: `root`, Pass: `rootpassword`)
- phpMyAdmin: [http://localhost:8080](http://localhost:8080)

### 3.2 Backend Setup (Laravel)
Configure and start the API server:

```bash
cd backend
composer install
cp .env.example .env
# Edit .env: Set DB_HOST=127.0.0.1, DB_PASSWORD=rootpassword, DB_DATABASE=content_improver
php artisan key:generate
php artisan migrate
php artisan serve
```
- API URL: [http://127.0.0.1:8000](http://127.0.0.1:8000)

### 3.3 Data Ingestion (Python)
Import `.docx` files into the database:

```bash
# In the root project folder
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install python-docx mysql-connector-python
# Ensure your .docx files are in the /articles folder
python import_docs.py
```

### 3.4 Automation Worker (Node.js)
Run the AI processing script:

```bash
cd worker
npm install
# Create a .env file with:
# GEMINI_API_KEY=your_key_here
# API_URL=http://127.0.0.1:8000/api
node index.js
```

### 3.5 Frontend Setup (React)
Launch the user interface:

```bash
cd frontend
npm install
npm run dev
```
- UI URL: [http://localhost:5173](http://localhost:5173)

---

# 4. Project Structure

```
/Article-process
├── backend/        # Laravel 11 (API & Business Logic)
├── frontend/       # React + Vite + Tailwind CSS (User Interface)
├── worker/         # Node.js + Puppeteer (Scraping & AI Logic)
├── articles/       # Raw .docx input files
├── docker-compose.yml # MySQL & phpMyAdmin config
├── import_docs.py  # Data import utility
└── README.md       # Project documentation
```

---

# 5. Tech Stack

- **Database:** MySQL 8.0 (Dockerized)
- **Backend:** PHP / Laravel 11
- **Frontend:** React / Tailwind CSS / Vite
- **AI/LLM:** Google Gemini 2.0 Flash
- **Automation:** Node.js / Puppeteer / Cheerio

---

# 6. Troubleshooting

- **CORS Errors:** Ensure `config/cors.php` in Laravel allows requests from `localhost:5173`.
- **429 Too Many Requests:** Gemini API Free Tier has rate limits. If the worker fails, wait 60 seconds and try again.
- **Docker Connection:** In Laravel's `.env`, use `DB_HOST=127.0.0.1` (not `localhost`) to connect to the mapped port correctly.